{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T13:25:24.675733900Z",
     "start_time": "2023-12-19T13:25:17.818754500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time:8.49 ms\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "version = \"21\"\n",
    "# 读入图像路径\n",
    "train_image_path = r\"..\\robotdetection-\"+version+r\"\\train\\images\"\n",
    "train_label_path = r\"..\\robotdetection-\"+version+r\"\\train\\labels\"\n",
    "valid_image_path = r\"..\\robotdetection-\"+version+r\"\\valid\\images\"\n",
    "valid_label_path = r\"..\\robotdetection-\"+version+r\"\\valid\\labels\"\n",
    "\n",
    "train_files = os.listdir(train_image_path)\n",
    "train_size = len(train_files)\n",
    "valid_files = os.listdir(valid_image_path)\n",
    "valid_size = len(valid_files)\n",
    "\n",
    "model = torch.load(\"model_csp3_800.pth\")\n",
    "count = 0\n",
    "\n",
    "start = time.time()\n",
    "for i, file in enumerate(train_files):\n",
    "    image = cv.imread(train_image_path + \"\\\\\" + file)\n",
    "    color_image = image\n",
    "    # print(color_image.shape)\n",
    "    image_norm = cv.normalize(image, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "    image_t = torch.from_numpy(np.array(image_norm, dtype=np.float32)).permute(2, 0, 1).unsqueeze(0)\n",
    "    pred = model(image_t.to('cuda')).squeeze().to('cpu').float()\n",
    "    count += 1\n",
    "end  = time.time()\n",
    "\n",
    "print(\"inference time:{:.2f} ms\".format((end-start)/count*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T13:26:27.877958800Z",
     "start_time": "2023-12-19T13:26:17.963101900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-10-8 Python-3.10.11 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29777\\Desktop\\paper\\object_detection\\code\\car_follow_diy\\yolov5\n",
      "inference time:12.19 ms\n"
     ]
    }
   ],
   "source": [
    "%cd ../yolov5\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "# 从摄像头中读入图片\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "from  ultralytics.utils.plotting import colors\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.augmentations import letterbox\n",
    "from utils.general import check_img_size\n",
    "from utils.general import non_max_suppression\n",
    "from utils.torch_utils import select_device\n",
    "from  utils.general import scale_boxes\n",
    "import pyrealsense2 as rs\n",
    "import cv2 as cv\n",
    "import time\n",
    "import  os\n",
    "\n",
    "# 打开摄像头，0表示使用默认的摄像头\n",
    "# 导入模型\n",
    "\n",
    "ROOT = r\"C:\\Users\\29777\\Desktop\\paper\\object_detection\\code\\car_follow_diy\\yolov5\" # yolopractice/YoloComputerCameraObjectDetection.py\n",
    "device = 0\n",
    "device = select_device(device)\n",
    "weights = ROOT + '/last.pt'\n",
    "dnn = False\n",
    "imgsz = (640, 640)\n",
    "data = ROOT + '/data/coco128.yaml',  # dataset.yaml path\n",
    "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=False)\n",
    "# torch.save(model,\"last_save.pt\")\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "# 创建一个VideoWriter对象\n",
    "version = \"17\"\n",
    "# 读入图像路径\n",
    "train_image_path = r\"..\\robotdetection-\"+version+r\"\\train\\images\"\n",
    "train_label_path = r\"..\\robotdetection-\"+version+r\"\\train\\labels\"\n",
    "valid_image_path = r\"..\\robotdetection-\"+version+r\"\\valid\\images\"\n",
    "valid_label_path = r\"..\\robotdetection-\"+version+r\"\\valid\\labels\"\n",
    "\n",
    "train_files = os.listdir(train_image_path)\n",
    "train_size = len(train_files)\n",
    "valid_files = os.listdir(valid_image_path)\n",
    "valid_size = len(valid_files)\n",
    "\n",
    "count = 0\n",
    "start = time.time()\n",
    "for i, file in enumerate(train_files):\n",
    "    # 从摄像头读取一帧图片\n",
    "    image = cv.imread(train_image_path + \"\\\\\" + file)\n",
    "\n",
    "    color_frame = image\n",
    "\n",
    "    # 将RGB图像数据转换为NumPy数组\n",
    "    color_image = np.asanyarray(color_frame)\n",
    "    im0  = color_image\n",
    "    # 图片预处理\n",
    "    im = letterbox(im0)[0]  # padded resize\n",
    "    im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    im = np.ascontiguousarray(im)  # contiguous\n",
    "    # 预测\n",
    "    im = torch.from_numpy(im).to(model.device)\n",
    "    im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "    im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(im.shape) == 3:\n",
    "        im = im[None]  # expand for batch dim\n",
    "    pred = model(im)\n",
    "    pred = non_max_suppression(pred, 0.25, 0.45, None, False, max_det=1000)\n",
    "    count = count + 1\n",
    "end  = time.time()\n",
    "    \n",
    "print(\"inference time:{:.2f} ms\".format((end-start)/count*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
